{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f0a3da",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0292164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyforest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af64eee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 3144 files [02:22, 22.10 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders # or import splitfolders\n",
    "input_folder = \"E:/projects/DFL-BundesligaDataShootout/dataset-20220903T082147Z-001/events-splitted-data/\"\n",
    "output = \"E:/projects/DFL-BundesligaDataShootout/dataset-20220903T082147Z-001/ready-data/\" #where you want the split datasets saved. one will be created if it does not exist or none is set\n",
    "\n",
    "splitfolders.ratio(input_folder, output=output, seed=42, ratio=(.7, .3)) # ratio of split are in order of train/val/test. You can change to whatever you want. For train/val sets only, you could do .75, .25 for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e832df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='E:/projects/DFL-BundesligaDataShootout/dataset-20220903T082147Z-001/ready-data/train'\n",
    "val_path='E:/projects/DFL-BundesligaDataShootout/dataset-20220903T082147Z-001/ready-data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "befb5560",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-80ae45babb0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\distribute\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msidecar_evaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Python module for evaluation loop.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# isort: off\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b66dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "\n",
    "          model = tf.keras.models.Sequential([ \n",
    "              tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "              tf.keras.layers.MaxPooling2D(2,2),\n",
    "              tf.keras.layers.BatchNormalization(),\n",
    "              tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "              tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "              tf.keras.layers.MaxPooling2D(2,2),\n",
    "              tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "              tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "              tf.keras.layers.MaxPooling2D(2,2),\n",
    "              tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "              tf.keras.layers.Flatten(),\n",
    "              tf.keras.layers.Dense(512,activation='relu'),\n",
    "              tf.keras.layers.Dropout(0.5),\n",
    "              tf.keras.layers.Dense(128,activation='relu'),\n",
    "              tf.keras.layers.Dense(2,activation='softmax')   # we used sigmoid also\n",
    "          ])\n",
    "\n",
    "\n",
    "          model.compile(optimizer='adam',\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy']) \n",
    "    \n",
    "\n",
    "          return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd453bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_1.fit(train_path,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    validation_data=val_path,\n",
    "                    steps_per_epoch= 100,\n",
    "                    validation_steps= 20 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
